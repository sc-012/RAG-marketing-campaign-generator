@echo off
REM Ollama Setup Script for DynamicRAGSystem (Windows)
echo ğŸ¦™ Setting up Ollama with Llama2:7b for DynamicRAGSystem
echo ========================================================

REM Check if Ollama is already installed
ollama --version >nul 2>&1
if errorlevel 1 (
    echo ğŸ“¦ Installing Ollama...
    echo Please download and install Ollama from https://ollama.ai/download
    echo After installation, run this script again.
    pause
    exit /b 1
) else (
    echo âœ… Ollama is already installed
    ollama --version
)

REM Start Ollama service
echo ğŸš€ Starting Ollama service...
start "Ollama Service" ollama serve

REM Wait for Ollama to start
echo â³ Waiting for Ollama to start...
timeout /t 5 /nobreak >nul

REM Pull Llama2:7b model
echo ğŸ“¥ Downloading Llama2:7b model (this may take a few minutes)...
ollama pull llama2:7b

REM Verify installation
echo ğŸ” Verifying installation...
ollama list | findstr "llama2:7b" >nul
if errorlevel 1 (
    echo âŒ Failed to install Llama2:7b model
    pause
    exit /b 1
) else (
    echo âœ… Llama2:7b model installed successfully!
)

REM Test the model
echo ğŸ§ª Testing the model...
ollama run llama2:7b "Hello, this is a test." >nul 2>&1
if errorlevel 1 (
    echo âŒ Model test failed
    pause
    exit /b 1
) else (
    echo âœ… Model is working correctly!
)

echo.
echo ğŸ‰ Ollama setup complete!
echo =========================
echo âœ… Ollama service is running
echo âœ… Llama2:7b model is ready
echo âœ… DynamicRAGSystem can now use local LLM
echo.
echo To test the model: ollama run llama2:7b "Your prompt here"
echo.
echo ğŸš€ You can now start the DynamicRAGSystem backend!
pause
